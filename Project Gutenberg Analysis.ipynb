{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Gutenberg Analysis\n",
    "\n",
    "Explain why and how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T21:55:23.595339Z",
     "start_time": "2018-03-23T21:55:23.480568Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "from datetime import datetime\n",
    "from metainfo import readmetadata\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, RNN\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T18:25:12.411749Z",
     "start_time": "2018-03-23T18:25:12.406613Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T18:32:18.607192Z",
     "start_time": "2018-03-23T18:32:18.313249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 56817 books in 0:00:00.289389\n",
      "(56817, 8)\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "meta_data = readmetadata()\n",
    "print('Read in ' + str(len(meta_data)) + ' books in ' + str(datetime.now() - time_start))\n",
    "print(meta_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T18:32:20.559834Z",
     "start_time": "2018-03-23T18:32:20.556632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'author', 'title', 'downloads', 'LCC', 'subjects',\n",
      "       'authoryearofbirth', 'authoryearofdeath'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(meta_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T22:11:05.301165Z",
     "start_time": "2018-03-23T22:11:05.263287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     22372\n",
      "2     14272\n",
      "3      7136\n",
      "0      4660\n",
      "4      3937\n",
      "5      1920\n",
      "6       924\n",
      "7       631\n",
      "8       383\n",
      "9       215\n",
      "10      150\n",
      "11      111\n",
      "12       46\n",
      "13       26\n",
      "14       14\n",
      "15        7\n",
      "16        7\n",
      "17        3\n",
      "20        1\n",
      "18        1\n",
      "25        1\n",
      "Name: subjects, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Investigating Metadata\n",
    "subs = meta_data['subjects'].str.len()\n",
    "print(len(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T18:32:22.345191Z",
     "start_time": "2018-03-23T18:32:22.317309Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_book_text(book_id=None):    \n",
    "    if not book_id:\n",
    "#         print('Please pass in a book_id.')\n",
    "        return\n",
    "    file_path = os.path.join(DATA_ROOT, 'books', str(book_id) + '.zip')\n",
    "    if not os.path.isfile(file_path):\n",
    "#         print('File Does Not Exist')\n",
    "        return\n",
    "    \n",
    "    with zipfile.ZipFile(file_path) as myzip:\n",
    "        # Assuming we are after the only/first file\n",
    "        with myzip.open(myzip.namelist()[0]) as myfile:\n",
    "            # This could be done in one line but split for readability\n",
    "            # Plus, this only needs to be run once per file and the results are then saved\n",
    "            try:\n",
    "                raw_data = myfile.read().decode('utf-8')\n",
    "                # This removes the Project Gutenberg Header\n",
    "                book_text = ''.join(raw_data.split('***')[2:])\n",
    "                # Removes new lines\n",
    "                book_text = book_text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "                return book_text\n",
    "            except:\n",
    "                return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T18:32:30.195827Z",
     "start_time": "2018-03-23T18:32:30.177725Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_books_text(meta_data):\n",
    "    file_name = os.path.join(DATA_ROOT, 'books.text.pkl.gz')\n",
    "    if os.path.isfile(file_name):\n",
    "        return pickle.load(gzip.open(file_name, 'rb'))\n",
    "    text = {}\n",
    "    num_books = len(meta_data)\n",
    "    start_time = datetime.now()\n",
    "    for counter, book_id in enumerate(meta_data['id']):\n",
    "        if counter % 1000 == 0:\n",
    "            print('Processing book %s of %s in %s' % (counter, num_books, datetime.now() - start_time))\n",
    "        book_text = get_book_text(book_id=book_id)\n",
    "        if book_text:\n",
    "            text[book_id] = book_text\n",
    "    pickle.dump(text, gzip.open(file_name, 'wb'), protocol=-1)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T21:58:23.884314Z",
     "start_time": "2018-03-23T21:58:21.690525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 930 books in 0:00:02.191003\n"
     ]
    }
   ],
   "source": [
    "time_start = datetime.now()\n",
    "text = get_all_books_text(meta_data)\n",
    "print('loaded ' + str(len(text)) + ' books in ' + str(datetime.now() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T21:50:08.961623Z",
     "start_time": "2018-03-23T21:50:08.955973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378296358\n"
     ]
    }
   ],
   "source": [
    "# Checking our length\n",
    "total_length = 0\n",
    "for key in text:\n",
    "    total_length += len(text[key])\n",
    "print(total_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to convert our data from human-readable strings to machine-readable integers. In order to do that we will be using a tokenizer. This converts strings into arrays of numbers where the numbers correspond to the n-most common words and the rest of the words are 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T21:55:47.398361Z",
     "start_time": "2018-03-23T21:55:47.392367Z"
    }
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T21:59:16.209104Z",
     "start_time": "2018-03-23T21:58:46.007776Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(text.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T22:31:26.920468Z",
     "start_time": "2018-03-23T22:31:26.886178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     22372\n",
      "2     14272\n",
      "3      7136\n",
      "0      4660\n",
      "4      3937\n",
      "5      1920\n",
      "6       924\n",
      "7       631\n",
      "8       383\n",
      "9       215\n",
      "10      150\n",
      "11      111\n",
      "12       46\n",
      "13       26\n",
      "14       14\n",
      "15        7\n",
      "16        7\n",
      "17        3\n",
      "20        1\n",
      "18        1\n",
      "25        1\n",
      "Name: subjects, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Preparing our data\n",
    "\n",
    "# Getting a smaller meta_data selection for testing\n",
    "# meta_data_ = meta_data[meta_data['id'].isin(text.keys())]\n",
    "\n",
    "meta_data_ = meta_data\n",
    "subs = meta_data_['subjects'].str.len()\n",
    "print(subs.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T22:31:31.686093Z",
     "start_time": "2018-03-23T22:31:31.614655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22372\n",
      "Fiction                                                       1416\n",
      "Poetry                                                         571\n",
      "English wit and humor -- Periodicals                           551\n",
      "Science fiction                                                315\n",
      "Questions and answers -- Periodicals                           216\n",
      "Illustrated periodicals -- France                              213\n",
      "Popular literature -- Great Britain -- Periodicals             202\n",
      "Detective and mystery stories                                  148\n",
      "Periodicals                                                    145\n",
      "Encyclopedias and dictionaries                                 143\n",
      "Children's periodicals, American                               129\n",
      "Drama                                                          128\n",
      "English fiction -- 19th century                                126\n",
      "American poetry                                                123\n",
      "American periodicals                                           121\n",
      "Essays                                                         115\n",
      "English poetry                                                 111\n",
      "Short stories                                                  105\n",
      "Western stories                                                102\n",
      "Fairy tales                                                    102\n",
      "French fiction -- Translations into English                     96\n",
      "French fiction -- 19th century                                  79\n",
      "Science -- Periodicals                                          78\n",
      "French literature                                               76\n",
      "World War, 1914-1918                                            74\n",
      "Finnish fiction -- 20th century                                 69\n",
      "World War, 1914-1918 -- Fiction                                 69\n",
      "English drama                                                   65\n",
      "Copyright -- United States -- Catalogs                          64\n",
      "French fiction                                                  60\n",
      "                                                              ... \n",
      "Embryology, Human                                                1\n",
      "Commercial catalogs -- Canada                                    1\n",
      "Missionaries -- Fiction                                          1\n",
      "Augustinian Canons                                               1\n",
      "Prussia (Germany) -- History -- 1640-1740 -- Fiction             1\n",
      "Newspaper vendors -- Juvenile fiction                            1\n",
      "Scheele, Carl Wilhelm, 1742-1786                                 1\n",
      "Canada -- History -- Rebellion, 1837-1838                        1\n",
      "Naval strategy                                                   1\n",
      "Folklore -- Austria -- Tyrol                                     1\n",
      "Cost and standard of living                                      1\n",
      "Yellow Fever -- Louisiana -- Shreveport -- 1873 -- Fiction       1\n",
      "Oratorio                                                         1\n",
      "Raleigh, Walter, Sir, 1552?-1618                                 1\n",
      "Thailand -- Description and travel                               1\n",
      "Theosophy -- Fiction                                             1\n",
      "Church and state -- Sweden                                       1\n",
      "Boys -- Conduct of life -- Juvenile fiction                      1\n",
      "Philippines -- Social conditions                                 1\n",
      "Gnosticism                                                       1\n",
      "Factories -- Drama                                               1\n",
      "Spain -- History -- Philip II, 1556-1598 -- Fiction              1\n",
      "Di, Renjie, 629-700 -- Fiction                                   1\n",
      "Moscheles, Felix, 1833-1917                                      1\n",
      "Paderewski, Ignace Jan, 1860-1941                                1\n",
      "Fairy tales -- Great Britain                                     1\n",
      "Portugal -- Social life and customs -- Poetry                    1\n",
      "Covenants -- Religious aspects                                   1\n",
      "Christian ethics                                                 1\n",
      "Creation -- Juvenile literature                                  1\n",
      "Name: subjects, Length: 7148, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "subjects = meta_data_[meta_data_['subjects'].str.len() ]\n",
    "subjects = subjects['subjects'].apply(lambda x: list(x)[0])\n",
    "print(len(subjects))\n",
    "\n",
    "print(subjects.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-23T22:02:02.880789Z",
     "start_time": "2018-03-23T22:02:02.856742Z"
    }
   },
   "outputs": [],
   "source": [
    "def basic_lstm_model(embedding_vector_length=32, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, embedding_vector_length, input_length=MAX_REVIEW_LEN))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
